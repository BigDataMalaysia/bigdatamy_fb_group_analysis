{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Meta with Big Data Malaysia\n",
    "Scraping the Big Data Malaysia Facebook group for fun. Profit unlikely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all the data\n",
    "This notebook assumes you have already prepared a flattened JSON file into `all_the_data.json`, which you would have done by:\n",
    "* Writing your oauth token into `oauth_file` according to the instructions in `pull_feed.py`.\n",
    "* Running `python pull_feed.py` to pull down the feed pages into the BigDataMyData directory.\n",
    "* Running `python flatten_saved_data.py > all_the_data.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "INPUT_FILE = \"all_the_data.json\"\n",
    "with open(INPUT_FILE, \"r\") as big_data_fd:\n",
    "\tbig_data = json.load(big_data_fd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is it big enough?\n",
    "Now we have all our data loaded into variable `big_data`, but can we really say it's Big Data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 1946 posts\n"
     ]
    }
   ],
   "source": [
    "print \"We have {} posts\".format(len(big_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! So data! Very big!\n",
    "\n",
    "Now we know we have that many items (rows I guess?), but how much variety do we have in this data? Put it a different way, how many different fields are there in each of those items?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 13 different field names\n"
     ]
    }
   ],
   "source": [
    "all_the_fields = set([y for y in x.keys() for x in big_data])\n",
    "print \"We have {} different field names\".format(len(all_the_fields))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([u'from', u'subscribed', u'privacy', u'id', u'actions', u'updated_time', u'to', u'likes', u'created_time', u'message', u'type', u'is_hidden', u'comments'])\n"
     ]
    }
   ],
   "source": [
    "print all_the_fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "* Get a cumulative activity timeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
